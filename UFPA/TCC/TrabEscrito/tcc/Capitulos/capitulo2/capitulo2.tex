%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% 

\chapter{Processamento de imagem}
\label{cap:processamento_imagens}

%----------------------------------------------------------------------------------------------------------------------------------------------------%
%
%


\section{Introdução ao Processamento de Imagens Digitais}
\label{sec:introdução}

A III revolução industrial, na década de 1970, proporcionou diversos avanços tecnológicos nas mais diversas áreas da ciência, inclusive abrindo espaço novos ramos de estudo, como por exemplo a Inteligência Artificial que teve seus princípios imaginado por Alan Turing mas que só pode ser propriamente desenvolvida depois dos avanços alcançados por esta revolução. Outra área que se beneficiou desta revolução foi a tecnologia de sensores (e.g, sensores ópticos, de luz, de temperatura, de pressão, de resistência entre outros) devido ao grande avanço no processo de fabricação de \textit{chips} e componentes tornando possível a digitalização desses dispositivos, aumento assim sua precisão e reduzindo seu tamanho a níveis microscópicos nos dias de hoje.

O avanço da tecnologia de sensores e armazenamento digital abriu possibilidades para diversas aplicações e dispositivos, inicialmente à nível militar e de pesquisa, como por exemplo a câmera digital que se tornou possível devido a criação de sensores de luminosidade mais precisos e principalmente ao armazenamento digital de informações em dispositivos de memória menores e com maior densidade, haja visto que o conceito de imagem digital reside no fato de que a imagem deve ser armazenada digitalmente.

Ao final de década e 1990 e início dos anos 2000 começou a popularização das câmeras digitais e seu uso e suas vantagens começaram a ser mais difundidos. Neste ponto as memórias digitais já haviam avançado o suficiente para que as pessoas pudessem tirar algumas dezenas/centenas de fotos com suas câmeras. Na década de 2010 as câmeras digitais entraram definitivamente para a vida das pessoas com a popularização dos \textit{smartphones} e paralelo a isso houve também um aumento desses dispositivos principalmente em aplicações relacionadas à segurança como monitoramento de tráfego nas cidades, controle de velocidade, segurança de propriedades privadas, entre outros. A popularização das câmeras digitais em diversas áreas acaba por gerar uma grande quantidade de conteúdo que muitas vezes não está organizado da melhor forma possível para interpretação do usuário.




\subsection{Por que utilizar processamento de imagem?}
\label{sub:porque_processamento_imagens}

Esse conteúdo gera a necessidade de técnicas de processamento e análise de imagem cada vez mais eficientes e robustas para que se possa aproveitar esse mundo de imagens geradas da melhor forma possível. Portanto, com o avanço da tecnologia de digitalização e armazenamento de imagens surge também a necessidade de pesquisa e melhorias nas técnicas para melhor aproveitar o material produzido, um exemplo prático é o reconhecimento automático de placas de automóveis em radares de detecção de velocidade para aplicação de multas. Em sistemas modernos o radar detecta que um veículo está acima do limite permitido e imediatamente tira uma foto da traseira do veículo, esta imagem é então processada por um algoritmo de segmentação de imagem que vai detectar a placa do veículo e posteriormente segmentar cada elemento da placa (números e letras) em imagens diferentes e enviar estas imagens para um algoritmo classificador que irá identificar a placa propriamente dita e enviar essa informação ao sistema principal para que a multa seja gerada para o dono do veículo.

O exemplo apresentado mostra uma das principais vantagens de utilizar processamento de imagem no dia-a-dia, a automatização de sistemas, proporcionando eficiência, fluidez e praticidade em atividades repetitivas que antes precisavam da intervenção humana para analisar visualmente e então tomar decisões, já não necessitam de intervenção com o advento da visão computacional, \cite{Shapiro2000}, entretanto para que as decisões sejam tomadas de forma correta e os efeitos desse tipo de automação sejam positivos é necessário que as técnicas empregadas atendam à demanda existente. Partindo dessa visão pode-se considerar a área de processamento de imagem como um meio para se chegar a visão computacional, onde máquinas analisam elementos visualmente para tomada de decisão. 


O uso de máquinas para tomada de decisões baseadas em imagens é importante não apenas para automatizar e tornar determinadas tarefas mais eficientes mas também para analisar imagens que não são visíveis ao olho humano (i.e, infra-vermelho e ultra-violeta). A Figura \ref{fig:espectro_luz} mostra o espectro electromagnético, onde é possível perceber que a luz visível ao olho humano é apenas uma pequena parte de todo o espectro e por isso a importância de sistemas computacionais eficientes para interpretar e analisar imagens do espectro não visível, como as de raio gamma e raios-x, muito comuns em estudos astronômicos.


\begin{figure}[h]
		\centering
		\includegraphics[scale=0.50]{./figuras/capitulo_2/espectro-luz.png}
		\caption{Espectro electromagnético.  Ilustração: Peter Hermes Furian / Shutterstock.com}
		\label{fig:espectro_luz}
	\end{figure} 

As seções seguintes irão detalhar os principais conceitos relacionados ao processamento digital de imagens bem como as principais técnicas existentes e suas aplicações, sendo reservado uma seção para segmentação de imagens, que é o foco principal deste trabalho.


\subsection{Definição e principais conceitos}
\label{sub:definicao}


\subsubsection{Definição}

(Gonzalez et. al) definem em \cite{Gonzalez} que processamento digital de imagens têm dois focos principais: (1) melhorar a qualidade para percepção humana e; (2) processar a imagem para armazenamento, transmissão e representação para percepção de máquinas autônomas. 

Ainda segundo \cite{Gonzalez}, não existem fronteiras bem definidas no campo de estudos entre processamento de imagens e visão computacional, entretanto pode-se considerar três tipos de processos informatizados nesse caminho: (1) baixo, (2) médio e (3) alto nível que serão detalhados a seguir:
	\begin{enumerate}
		\item \textbf{Processos de baixo nível:} envolve operações primitivas com imagens, tais como redução de ruído, aprimoramento de contraste e aguçamento de imagem. Este tipo de processo tem como característica o fato de que ambas entrada e saída são imagens.
		\item \textbf{Processos de médio nível:} este processo envolve operações mais complexas como segmentação (particionamento da imagem em regiões ou objetos) e descrição desses objetos em um formato entendível para o processamento por computadores, além de classificação (reconhecimento) desses objetos. Normalmente as entradas deste processo são imagens e as saídas são atributos extraídos das imagens (e.g, bordas, contornos, e a identidade de objetos).
		\item \textbf{Processos de alto nível:} este processo envolve a interpretação de objetos identificados e/ou reconhecidos pelas etapas anteriores, ou seja, dar significado a partir de funções cognitivas associadas à visão.
	\end{enumerate}


\subsubsection{Conceitos básicos}
O conceito de processamento digital de imagem pode ser definido como o conjunto formado pelos três processos acima citados, criando assim uma ferramenta robusta capaz de extrair informações do mundo real, adequá-las a um formato apropriado (baixo nível), extrair informações e parâmetros (médio nível), analisar e tomar decisões com base nas informações coletadas (alto nível). Tomando o exemplo dos radares de controle de velocidade mencionados na seção anterior para ilustrar o uso desses níveis na hora de estruturar uma ferramenta é possível fazer as seguintes associações:

	\begin{itemize}
		\item \textbf{Processo de baixo nível:} aplicação de filtros para melhorar o contraste da imagem a fim de facilitar a identificação de onde está a placa do automóvel.		
		\item \textbf{Processo de médio nível:} segmentar as letras/números da placa do veículo, transformar cada caractere da placa em um arquivo, por exemplo, por fim classificá-los (i.e, identificar quais são as letras/números presentes naquela placa em análise).
		\item \textbf{Processo de alto nível:} de posse dos caracteres, o sistema desenvolvido irá identificar (reconhecer) que aquele array de caracteres naquela ordem significa a placa de um automóvel e enviará a informação da placa (no formato correto) para o sistema que irá gerar o auto de infração.  
	\end{itemize}

Para aprofundar os conhecimentos em processamento digital de imagens é necessário primeiramente o entendimento de alguns conceitos básicos que serão utilizados posteriormente para o entendimento de técnicas mais complexas, os principais conceitos são:

	\begin{itemize}
		\item \textbf{Imagem:} segundo \cite{Gonzalez}, uma imagem é definida como uma função bi-dimensional, $f(x,y)$, onde $x$ e $y$ são coordenadas espaciais e a amplitude de $f$ em qualquer par de coordenadas $(x,y)$ é chamada de intensidade ou nível de cinza da imagem naquele ponto.
		\item \textit{\textbf{Pixel:}} É a menor unidade de uma imagem digital, ou seja, corresponde a um par de coordenadas $(x,y)$, representando um ponto espacial dentro da imagem.
		\item \textbf{Texel:} é o elemento fundamental de uma textura, formado por um conjunto de \textit{pixels} que agrupados segundo uma ordem lógica formam a textura de uma imagem.
		\item \textbf{Textura:}	de acordo com \cite{Shapiro2000} a textura de uma imagem é um conjunto de métricas calculadas no processamento da imagem designadas para quantificar a textura perceptível de uma imagem. Essa textura guarda informações referentes ao arranjo espacial de cores ou intensidades em uma imagem ou em uma região selecionada da imagem.
		\item \textbf{Níveis de cinza:} níveis para medir a intensidade (valor) de um \textit{pixel} em uma imagem digital, normalmente são valores inteiros no intervalo $[0,255]$
		\item \textbf{Filtragem espacial:} em sistemas lineares, corresponde à operação de convolução ou correlação (no domínio espacial) entre uma imagem e uma máscara (filtro), onde esta pode ter diversos formatos utilizados para suavização ou aguçamento de imagens, essa operação será detalhada logo abaixo.
		\item \textbf{\textit{Pixel} vizinho:} Um \textit{pixel x} é considerado vizinho do \textit{pixel p} se, e somente se, a distância entre $x$ e $p$ for igual a 1 $\therefore$ ($ d_{s \rightarrow p} = 1 $).
		\item \textbf{Conectividade \textit{pixels}:} Em imagens digitais existem duas possibilidades de um pixel estar conectado à outro, a conexão pode ser do tipo 4-conectado ou 8-conectado, na primeira considera-se conectados ao pixel $p$ apenas os \textit{pixels} vizinhos na vertical e na horizontal, enquanto que na segunda considera-se os conectados ao \textit{pixel} $p$ os vizinhos em todas as direções (vertical, horizontal e diagonal).
	\end{itemize}



\subsubsection{Operações básicas}

Para realizar qualquer operação em uma imagem é necessário primeiro entender o conceito de janela ou elemento estruturante, este elemento consiste em uma matriz, que representa uma máscara para filtragem ou um operador morfológico.  Existem dois  tipos principais de operações fundamentais que podem ser efetuadas sobre uma imagem e são elas: (1) correlação e convolução, onde a diferença entre a primeira e a segunda é que na convolução a máscara é rotacionada em 180º, por definição da própria operação, \cite{HAYKIN2001} e (2) operações morfológicas. O primeiro tipo de operação envolve cálculos matemáticos enquanto que o segundo está associado com operações lógicas.

A forma mais comum do uso das janelas são utilizar elementos quadrado ($N_{linhas} = N_{colunas}$), com $N$ sendo um inteiro ímpar para que exista o elemento central, isto ocorre devido ao seu funcionamento que se dá da seguinte maneira: a janela é posicionada sobre parte da imagem de tal forma que seu \textit{pixel} central fique sobre o primeiro \textit{pixel} (e.g, ponto $x_{1},y_{1}$) da imagem de entrada e partir disso os elementos da janela são multiplicados  por seus correspondentes na imagem, os resultados são então somados e o resultado final é armazenado no ponto $x_{1},y_{1}$ da imagem de saída, este procedimento será explicado com mais detalhes.

Apesar de serem muito utilizadas, operações com janela geram um problema no que diz respeito às bordas da imagem que ocorre quando o pixel central do operador (janela) está sobre os \textit{pixels} mais extremos da imagem fazendo com que parte da janela fique para fora da imagem, o que acarreta em uma operação sem valor para o resultado final pois a janela estaria atuando em cima de valores que não fazem parte da função $f(x,y)$ (imagem). Para resolver este problema existem 2 abordagens clássicas:
	\begin{enumerate}
		\item Expandir a imagem de tamanho, em $a = \frac{(m-1)}{2}$ linhas em cima e embaixo e $b = \frac{(n-1)}{2}$ colunas nas laterais, onde $N$x$M$ é o tamanho da janela.
		\item Reduzir a imagem de saída em $a = \frac{(m-1)}{2}$ linhas em cima e embaixo e $b = \frac{(n-1)}{2}$ colunas nas laterais da imagem utilizando o como \textit{pixel} inicial o ponto $(x+a,y+b)$
	\end{enumerate}

\paragraph{Correlação e convolução}

Nas operações de correlação e convolução a janela representa o filtro ao qual a imagem será submetido, este procedimento é muito utilizado para realizar suavizações (filtros do tipo passa-baixa) ou aguçamentos na imagem (filtros do tipo passa-alta) devido à sua facilidade de implementação computacional. Os filtros mais comumente utilizados são matrizes quadradas e de tamanho ímpar para que haja a presença de um elemento central e caso o filtro $h (m\ x\ n)$, onde $m$ e $n$ são o tamanho do filtro, seja simétrico as operações de convolução e correlação são equivalentes. Estas operações são muito utilizadas na etapa de pré-processamento de imagens, para eliminação de ruído, realce de bordas, suavização de imagens, existem diversos tipos de filtros com objetivos específicos (e.g, detecção de texturas) que serão explicados mais detalhadamente adiante neste capítulo.

A Figura \ref{fig:exemplo_filtro} mostra um exemplo prático da convolução da Imagem $I$ pelo filtro $h$, resultando na imagem de saída $Y$, neste exemplo foi utilizada a abordagem (2), cita acima, para contornar o problema de borda. Generalizando este procedimento é possível chegar à Equação \ref{eq:saida_filtragem} para definir de forma genérica a imagem $Y$ em função da imagem de entrada $I$ e do tamanho do filtro.


	\begin{figure}[!h]
		\centering
		\includegraphics[scale=1]{./figuras/capitulo_2/exemploFiltro.pdf}
		\caption{Exemplo de convolução/correlação 2-D}
		\label{fig:exemplo_filtro}
	\end{figure}

\begin{equation}
	Y(x,y) = \sum_{s=1}^{m} \sum_{t=1}^{n} I([(x+a)-\frac{m+1}{2}+s],[(y+b)-\frac{n+1}{2}+t])h(s,t)
	\label{eq:saida_filtragem}
\end{equation}

\paragraph{Morfologia}

Dentro do conjunto de operações básicas existem também as operações de erosão ($\ominus$) e dilatação ($\oplus$) da imagem, utilizadas, respectivamente, para remover objetos menores que o elemento estruturante e preencher espaços vazios, entretanto essas operações resultam, respectivamente, em encolhimento e aumento indesejável dos objetos restantes nas imagens e para resolver este problema utiliza-se as duas técnicas: (1) abertura e (2) fechamento. Considere a matriz $A$ e o elemento estruturante $B$, ambos binários, erosão e dilatação de $A$ por $B$ são representadas, respectivamente, por $A \ominus B$ e a dilatação por $A \oplus B$ e podem ser definidas como:

	\begin{itemize}
		\item \textbf{Erosão:} O elemento estruturante ``anda'' pela imagem tendo como origem seu elemento central, como se fosse um filtro, e para cada posição $(x,y)$ de $B$ dentro de $A$, a saída $g(x,y)$ será igual a 1 se os elementos diferentes de zero de $B$ e de $A$ para aquela janela (que possui tamanho igual ao de $B$) coincidirem, ou seja, se $B$ encaixar em $A'$.
		
		A Figura \ref{fig:exemplo_erosao} ilustra $A \ominus B$, na Figura \ref{fig:exemplo_erosao_a} é possível visualizar que os elementos em verde de $B$ coincidem com os elementos em verde de $A$ (considerando a origem de $B$ o ponto $B(2,2)$, entretanto há elementos em $B$ (marcados em vermelho) que estão fora de $A$ ou não coincidem com elementos de $A$ diferentes de zero, nesse caso a erosão não ocorre e portanto $g(1,1) = 0$.
		\item \textbf{Dilatação:} O algoritmo é parecido com o da erosão à exceção de que para que a saída seja '1' o elemento estruturante $B$ não precisa encaixar na janela atual de $A$ mas apenas tocá-la. A Figura \ref{fig:exemplo_dilatacao} ilustra a dilatação de $A$ por $B$. É possível visualizar na Figura \ref{fig:exemplo_dilatacao_a} que nenhum elemento não nulo de $A$ coincide com os elementos não nulos de $B$, logo $g(1,6) = 0$, enquanto que na Figura \ref{fig:exemplo_dilatacao_b} o elemento $B(3,2)$ coincide com um dos elementos não nulos de $A$, portanto $g(2,5) = 1$.
		
		
	\end{itemize}

	\begin{figure}[!h]
		\centering
		\includegraphics[scale=1.2]{./figuras/capitulo_2/exemploErosaoBase.pdf}
		\caption{Matriz A e elemento estruturante B}
		\label{fig:exemplo_morfologia_base}
	\end{figure}

	\begin{figure}[!h]
		\centering
		\subfloat[Caso onde não ocorre a erosão]{
		\includegraphics[scale=0.85]{./figuras/capitulo_2/exemploErosaoA.pdf}
		\label{fig:exemplo_erosao_a}}
		\hspace*{0.1cm}
		\vspace*{0.1cm}
		\subfloat[Caso onde ocorre a erosão]{
		\includegraphics[scale=0.85]{./figuras/capitulo_2/exemploErosaoB.pdf}
		\label{fig:exemplo_erosao_b}}	
		\vspace{0.1cm}
		\subfloat[Resultado final de s$A \ominus B$]{
		\includegraphics[scale=1]{./figuras/capitulo_2/exemploErosao.pdf}
		\label{fig:exemplo_erosao_final}}	
		\caption{Erosão de $A$ por $B$. A Figura \ref{fig:exemplo_erosao_a} mostra o caso em que a erosão não ocorre, a Figura \ref{fig:exemplo_dilatacao_b} mostra o caso em que a erosão ocorre e por fim a Figura \ref{fig:exemplo_erosao_final} mostra o resultado final de $A \ominus B$.}
		\label{fig:exemplo_erosao}
	\end{figure}
	
	\begin{figure}[!h]
		\centering
		\subfloat[Caso onde não ocorre a dilatação]{
		\includegraphics[scale=0.85]{./figuras/capitulo_2/exemploDilatacaoA.pdf}
		\label{fig:exemplo_dilatacao_a}}
		\hspace*{0.1cm}
		\vspace*{0.1cm}
		\subfloat[Caso onde ocorre a dilatação]{
		\includegraphics[scale=0.85]{./figuras/capitulo_2/exemploDilatacaoB.pdf}
		\label{fig:exemplo_dilatacao_b}}	
		\vspace{0.1cm}
		\subfloat[Resultado final de s$A \ominus B$]{
		\includegraphics[scale=1]{./figuras/capitulo_2/exemploDilatacao.pdf}
		\label{fig:exemplo_dilatacao_final}}	
		\caption{Dilatação de $A$ por $B$. A Figura \ref{fig:exemplo_dilatacao_a} mostra o caso em que a dilatação não ocorre, a Figura \ref{fig:exemplo_dilatacao_b} mostra o caso em que a dilatação ocorre e por fim a Figura \ref{fig:exemplo_erosao_final} mostra o resultado final de $A \oplus B$.}
		\label{fig:exemplo_dilatacao}
	\end{figure}


\subsection{Aplicações de processamento de imagem}
\label{sub:aplicacoes}

Existem diversas área em que é possível aplicar processamento digital de imagem, seja para automatizar processos ou melhorar a qualidade de um serviço, por exemplo, na automação industrial para otimizar a seleção de produtos  ou identificar falhas na linha de montagem, na compressão de vídeos e imagens para transmissão em redes (i.e, com a popularização dos \textit{smartphones} e das redes móveis a necessidade de reduzir largura de banda na transmissão de arquivos multimídia aumentou nos últimos anos), na digitalização e classificação automática de textos (i.e, permitindo assim a busca em documentos que não foram gerados digitalmente), em segurança usando reconhecimento facial para identificação de pessoas autorizadas, na restauração de imagens que sofreram desgaste do tempo, na área forense usando técnicas que provem, por exemplo, que uma determinada foto foi tirada com uma câmera específica ou que uma imagem foi adulterada, ajudando assim em inquéritos policiais. Abaixo está uma lista de algumas das principais sub-áreas que compõem as aplicações acima citadas:
	\begin{itemize}
		\item Modelagem de imagem
		\item Restauração de imagem
		\item Segmentação
		\item Interpolação
		\item Reconhecimento de face
		\item Codificação de imagem/vídeo
		\item Sistemas de \textit{eye-tracking}
		\item Super resolução
		\item Identificação de dispositivo
		\item Verificação de Adulteração
		\item Redução de ruído
		\item Marca d'água digital
	\end{itemize}

Além das aplicações mencionadas, a área de visão computacional \cite{Shapiro2000} tem ganhado destaque nos últimos anos por ajudar a analisar situações que antes não eram possíveis, como por exemplo os vídeos em primeira pessoa que apresentam desafios não previstos por técnicas de processamento de imagem inicialmente projetadas para fotos/vídeos feitos por uma terceira pessoa fora da cena. Estes tipos de vídeos apresentam desafios como: (1) objetos que somem e reaparecem em cena inesperadamente (2) borrão na câmera causados por sujeira ou água (comum em vídeos de esportes) conforme descrito em \cite{Bambach2013}, o autor também descreve os principais avanços recentes em algoritmos de visão computacional para o campo específico de vídeos em primeira pessoa.

A popularização e redução do custo de câmeras digitais e \textit{smartphones} permitiu a criação de redes sem-fio de câmeras, criando a demanda por algoritmos de visão computacional que se adequem às dificuldades desses dispositivos como: (1) baterias com diferentes capacidades, (2) processadores limitados e (3) antenas com capacidade limitada. Em \cite{Radke2010} o autor explica os principais algoritmos utilizados em visão computacional distribuída.

\section{Segmentação de imagens}
\label{sec:segmentacao}

A área de processamento de imagem é bastante ampla e suas técnicas podem ser aplicadas em diversas áreas para distintos fins (e.g, automação, práticas forense, restauração, análise cognitiva, etc.) e até agora essas áreas foram apenas citadas e suas principais aplicações foram descritas. Nesta seção serão detalhados os tipos de segmentação de imagem, sendo esta a área de interesse deste trabalho, existentes e as principais técnicas utilizadas.

O desenvolvimento de uma aplicação deve ser pensado de forma a atender as demandas requisitadas e em todas os tipos de problemas, desde os mais complexos aos mais simples. Duas variáveis são cruciais nesta etapa: (1) tempo e (2) eficiência, estas compõem o grande desafio no desenvolvimento de novas soluções pois cada vez mais busca-se reduzir o tempo de execução de uma determinada tarefa para aumentar sua eficiência (i.e, realizar mais tarefas num mesmo intervalo de tempo).

Dividir um imagem em regiões de interesse distintas ou simplesmente separar um objeto do fundo é um dos processos mais importantes para análise de imagem pois é nele que são retirados da imagem original aquilo que será de fato utilizado para o processamento final, reduzindo assim o tempo gasto na execução de algoritmos posteriores bem como facilitando o trabalho de extrair informações.  Esse processo irá assinalar valores para cada \textit{pixel} da imagem (onde regiões distintas possuem valores iguais) para facilitar a diferenciação entre as regiões de interesse.  Essa diferenciação entre as regiões ocorre em função de três propriedades da imagem: (1) cor, (2) intensidade e (3) textura da imagem, portanto a escolha de qual técnica será utilizada deve ocorrer após um estudo do domínio do problema.

O conceito de região é importante pois normalmente regiões representam objetos em uma imagem. Gonzáles \cite{Gonzalez} mostra que uma imagem $R$ pode ser dividida em $n$ sub-regiões, $ R_{1}, R_{2},\dots, R_{n} $ tal que:

	\begin{enumerate}
		\item $ \bigcup_{i=1}^{n}R_{i} = R $.
		\item $ R_{i}$ é um conjunto conectado, $i = 1, 2,\dots, n $.
		\item $ R_{i} \cap R_{j} = \emptyset $ para todo $i$ e $j$, onde $ i \neq j $.
		\item $ Q(R_{i}) = VERDADEIRO\ para\  i = 1, 2,\dots, n $.
		\item $ Q(R_{i} \cup R_{j}) = FALSO $, onde $ i \neq j $.
	\end{enumerate}
%
onde $Q(R_{k})$ representa a função (ou propriedade) que deve ser satisfeita pelos \textit{pixels} pertencentes à $R_{k}$ (e.g, se todos os \textit{pixels} da região $R_{i}$ tiverem a mesma intensidade), $\emptyset$ é o conjunto vazio, $\cup\ e\ \cap$ representam, respectivamente, a união e a intersecção entre duas regiões distintas. Duas regiões $R_{i}\ e\ R_{j}$ são adjacentes se a união entre elas forma um conjunto conectado. 

Este é portanto um dos ramos mais estudados em processamento de imagem com diversas técnicas consolidadas (\cite{Khan2014,Chauhan2014,Jain1993,Saraswathi2013,Acharya2013}) e novas abordagens surgindo, algumas específicas para determinados problemas, para mais detalhes sobre algumas delas o leitor deve verificar (\cite{Huang2011,Yi2012,Deshmukh2014,Senthilkumaran2009,Raut2009}).

\subsection{Classificação das técnicas de segmentação}
\label{sub:tecnicas_segmentacao}

A otimização pode ser feita ao longo de várias etapas do desenvolvimento de uma solução, para o caso específico de processamento de imagens é comum tentar encontrar técnicas que sejam o mais específico possível para solucionar problemas e utilizar abordagens que ponderem o tempo em detrimento de algum outro fator menos relevante (e.g, qualidade, tamanho, modelo de cores).

Em relação à escolha de qual técnica de segmentação utilizar, três tipos devem ser considerados em termos de tempo, esforço e custo, são eles:
	
	\begin{enumerate}
		\item \textbf{Técnicas Automáticas:} muito utilizadas para segmentar objetos com geometria uniforme (ou quase uniforme) em imagens pré-determinadas (e.g, separar moedas do fundo, separar células, contar caixas em uma estante para controle de estoque, identificar produtos fora do padrão de qualidade especificado). Tais situações requerem algoritmos rápidos, entretanto normalmente trabalham com uma heurística refinada para que se obtenha o desempenho desejado. Não necessitam de intervenção humana, o sistema recebe a imagem de entrada e automaticamente separa os objetos de interesse.
		\item \textbf{Técnicas Semi-automáticas:} são técnicas em que o usuário insere alguma informação (heurística) antes do processamento para facilitar a segmentação, como por exemplo, marcar os objetos de interesse, delimitar uma região da imagem onde o algoritmo irá atuar. A heurística de entrada permite a segmentação de imagens mais complexas (e.g, o fundo não é uniforme, os objetos de interesse possuem o mesmo formato e/ou cor que objetos que não são de interesse). A técnica em estudo neste trabalho (\cite{Protiere2007}) pode ser classificada nesta categoria.
		\item \textbf{Técnicas Manuais:} são utilizadas quando os algoritmos existentes não são suficientes para extrair a informação desejada da imagem (dificilmente essa situação ocorre na prática), normalmente são utilizados softwares especiais (\cite{photoshop}) de edição de imagem, onde o usuário deve manualmente marcar todas as regiões da imagem (normalmente fazendo isso \textit{pixels} a \textit{pixel}. Este tipo de técnica apresenta um resultado ideal mas na maioria dos casos é inviável porque necessita de muito tempo (principalmente para imagens \textit{Full HD (1080x1920 pixels)} e acarreta em custo com a mão de obra especializada para desenvolver as tarefas.
	\end{enumerate}	 

\subsection{Tipos de segmentação}
\label{sub:tipos_segmentação}
Khan \cite{Khan2014} mostra uma categorização das principais técnicas de segmentação de imagem de acordo com a ideia principal por trás dos algoritmos, o autor sugere que a segmentação de imagens pode ser baseada em:
	\begin{enumerate}
		\item \textbf{Borda:} Este tipo de segmentação realiza detecção de bordas para separar os objetos do fundo da imagem utilizando o fato de que a intensidade dos \textit{pixels} muda abruptamente na borda dos objetos. Os métodos clássicos para detecção de borda são: (1) baseados no gradiente (derivada de $1^{a}$ ordem, (2) cruzamento de zeros (derivada de $2^{a}$ ordem), (3) laplaciano da Gaussiana, (4) detectores de borda Gaussianos e (5) detectores de bordas coloridas \cite{Lakshmi2010}. A forma mais simples de realizar detecção de borda é primeiramente realizar detecção de linhas utilizando máscaras (i.e, filtros) capazes de identificar a mudança de intensidade, por exemplo para detecção de pontos isolados a máscara a ser utilizada será $ \Big[ \begin{smallmatrix} 1 & 1 & 1 \\ 1 & -8 & 1 \\ 1 & 1 & 1 \end{smallmatrix} \Big] $, enquanto que para detecção de linhas, as máscaras serão $ \Big[ \begin{smallmatrix} 1 & -2 & 1 \\ 1 & -2 & 1 \\ 1 & -2 & 1 \end{smallmatrix} \Big] $, $ \Big[ \begin{smallmatrix} 1 & 1 & 1 \\ -2 & -2 & -2 \\ 1 & 1 & 1 \end{smallmatrix} \Big] $ e $ \Big[ \begin{smallmatrix} -2 & 1 & 1 \\ 1 & -2 & 1 \\ 1 & 1 & -2 \end{smallmatrix} \Big] $ para linhas na horizontal, vertical e diagonal, respectivamente.
		\item \textbf{Limiar:} esta é a segmentação mais simples, escolhe-se um valor $T$ e os \textit{pixels} abaixo de $T$ ($ R(x,y) \leq T$) são marcados como ``preto'' (ou $0$) e os valores acima de $T$ ($ R(x,y) \geq T$) são marcados como ``branco'' (ou $255$ para imagens de 8 \textit{bits}). Entretanto para que este processo seja eficiente é necessário que a escolha de $T$ seja feita de forma automática, um dos algoritmos mais conhecidos e utilizado por muito tempo foi criado por Otsu \cite{Otsu1979}. Sezgin  \cite{Sezgin2004} faz uma comparação entre 40 algoritmos baseados em limiar (\textit{threshold}). 
		\item \textbf{Região:} uma região de uma determinada imagem pode ser descrita como um conjunto de \textit{pixels} conectados (ver seção \ref{sub:definicao}) e tem um papel muito importante na segmentação pois regiões normalmente significam objetos de interesse. Existem três categorias principais para este tipo de segmentação: (1) crescimento de região, (2) divisão de região e (3) fusão de região  \cite{Kaganami2009}. \textit{Pixels} pertencentes a uma mesma região serão marcados, respeitando o princípio de que um pixel não pode pertencer a duas regiões.
		
	\end{enumerate}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%