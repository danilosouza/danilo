Automatically generated by Mendeley Desktop 1.13.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Otsu1979,
abstract = {A nonparametric and unsupervised method ofautoma- tic threshold selection for picture segmentation is presented. An optimal threshold is selected by the discriminant criterion, namely, so as to maximize the separability of the resultant classes in gray levels. The procedure is very simple, utilizing only the zeroth- and the first-order cumulative moments of the gray-level histogram. It is straightforward to extend the method to multithreshold problems. Several experimental results are also presented to support the validity of the method.},
author = {OTSU, NOBUYUKI},
doi = {10.1109/TSMC.1979.4310076},
file = {:C$\backslash$:/Users/Danilo/Documents/GitHub/danilo/UFPA/TCC/Documentos/otsu.pdf:pdf},
isbn = {0018-9472},
issn = {0018-9472},
journal = {IEEE Trans. Syst. Man. Cybern.},
number = {1},
pages = {62--66},
pmid = {4310076},
title = {{A Threshold Selection Method from Gray-Level Histograms}},
volume = {9},
year = {1979}
}
@article{Liu2009,
abstract = {Otsu method is one of the most successful methods for image thresholding. This paper proves that the objective function of Otsu method is equivalent to that of K-means method in multilevel thresholding . They are both based on a same criterion that minimizes the within-class variance. However, Otsu method is an exhaustive algorithm of searching the global optimal threshold, while K-means is a local optimal method. Moreover, K-means does not require computing a gray-level histogram before running, but Otsu method needs to compute a gray-level histogram firstly. Therefore, K-means can be more efficiently extended to multilevel thresholding method, two-dimensional thresholding method and three-dimensional method than Otsu method. This paper proved that the clustering results of K-means keep the order of the initial centroids with respect to one-dimensional data set. The experiments show that the k-means thresholding method performs well with less computing time than Otsu method does on three dimensional image thresholding.},
author = {Liu, Dongju and Yu, Jian},
doi = {10.1109/HIS.2009.74},
file = {:C$\backslash$:/Users/Danilo/Documents/GitHub/danilo/UFPA/TCC/Documentos/05254345.pdf:pdf},
isbn = {9780769537450},
journal = {Proc. - 2009 9th Int. Conf. Hybrid Intell. Syst. HIS 2009},
keywords = {K-mean,K-means thresholding,Otsu method,Three-dimensional thresholding,Two-dimensional thresholding},
number = {2},
pages = {344--349},
title = {{Otsu method and K-means}},
volume = {1},
year = {2009}
}
@article{Protiere2007,
abstract = {An interactive algorithm for soft segmentation of natural images is presented in this paper. The user first roughly scribbles different regions of interest, and from them, the whole image is automatically segmented. This soft segmentation is obtained via fast, linear complexity computation of weighted distances to the user-provided scribbles. The adaptive weights are obtained from a series of Gabor filters, and are automatically computed according to the ability of each single filter to discriminate between the selected regions of interest. We present the underlying framework and examples showing the capability of the algorithm to segment diverse images.},
author = {Protiere, Alexis and Sapiro, Guillermo},
doi = {10.1109/TIP.2007.891796},
file = {:C$\backslash$:/Users/Danilo/Documents/GitHub/danilo/UFPA/TCC/Documentos/2007\_Interactive Image Segmentation via adaptive wieghted distances.pdf:pdf},
isbn = {6126267370},
issn = {10577149},
journal = {IEEE Trans. Image Process.},
keywords = {Adaptive weights,Distance functions,Interactive segmentation,Linear complexity,Natural images},
number = {4},
pages = {1046--1057},
pmid = {17405436},
title = {{Interactive image segmentation via adaptive weighted distances}},
volume = {16},
year = {2007}
}
@article{Canny1986,
abstract = {This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we derive a single operator shape which is optimal at any scale. The optimal detector has a simple approximate implementation in which edges are marked at maxima in gradient magnitude of a Gaussian-smoothed image. We extend this simple detector using operators of several widths to cope with different signal-to-noise ratios in the image. We present a general method, called feature synthesis, for the fine-to-coarse integration of information from operators at different scales. Finally we show that step edge detector performance improves considerably as the operator point spread function is extended along the edge.},
author = {Canny, J},
doi = {10.1109/TPAMI.1986.4767851},
file = {:C$\backslash$:/Users/Danilo/Documents/GitHub/danilo/UFPA/TCC/Documentos/04767851.pdf:pdf},
isbn = {978-1-4244-7657-2},
issn = {0162-8828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
number = {6},
pages = {679--698},
pmid = {21869365},
title = {{A computational approach to edge detection.}},
volume = {8},
year = {1986}
}
@article{Patwardhan2008,
abstract = {A framework for robust foreground detection that works under difficult conditions such as dynamic background and moderately moving camera is presented in this paper. The proposed method includes two main components: coarse scene representation as the union of pixel layers, and foreground detection in video by propagating these layers using a maximum-likelihood assignment. We first cluster into "layers" those pixels that share similar statistics. The entire scene is then modeled as the union of such non-parametric layer-models. An in-coming pixel is detected as foreground if it does not adhere to these adaptive models of the background. A principled way of computing thresholds is used to achieve robust detection performance with a pre-specified number of false alarms. Correlation between pixels in the spatial vicinity is exploited to deal with camera motion without precise registration or optical flow. The proposed technique adapts to changes in the scene, and allows to automatically convert persistent foreground objects to background and re-convert them to foreground when they become interesting. This simple framework addresses the important problem of robust foreground and unusual region detection, at about 10 frames per second on a standard laptop computer. The presentation of the proposed approach is complemented by results on challenging real data and comparisons with other standard techniques.},
author = {Patwardhan, Kedar and Sapiro, Guillermo and Morellas, Vassilios},
doi = {10.1109/TPAMI.2007.70843},
file = {:C$\backslash$:/Users/Danilo/Documents/GitHub/danilo/UFPA/TCC/Documentos/2008\_Robust Foreground Detection in video using pixels layers.pdf:pdf},
isbn = {0162-8828 (Print)},
issn = {01628828},
journal = {IEEE Trans. Pattern Anal. Mach. Intell.},
keywords = {Background subtraction,Foreground detection,Layer tracking,Scene analysis,Surveillance,Video analysis},
number = {4},
pages = {746--751},
pmid = {18276979},
title = {{Robust foreground detection in video using pixel layers}},
volume = {30},
year = {2008}
}
